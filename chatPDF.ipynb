{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xMrb66-7wlq"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf2 langchain google-generativeai chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers > /dev/null"
      ],
      "metadata": {
        "id": "LJB6UtZaiWOw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as palm\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.llms import GooglePalm"
      ],
      "metadata": {
        "id": "YYx6wPo79Ju4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this key is deleted, use your own key!\n",
        "api_key='AIzaSyD14MM7JXldM2VGqh45YkyxF2VAa5IJ0fQ'"
      ],
      "metadata": {
        "id": "K9MdFQvx-yTA"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload as many pdf documents as you want, whole directory will get loaded\n",
        "loader = DirectoryLoader('/content', glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
        "# this process takes time, be patient\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "MhbtVd7dBUPT"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "id": "7plCWSbnCW89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 200,\n",
        ")"
      ],
      "metadata": {
        "id": "nDD5YgBYg64z"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "ftJsuYs5iWJm"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[600]"
      ],
      "metadata": {
        "id": "0PXIN1CxiWMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "# Equivalent to SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "tdkfFZ-LG4IU"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Database"
      ],
      "metadata": {
        "id": "G4LQeYV0CQk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Supplying the persistant directory will store the embeddings on disk\n",
        "\n",
        "pers_dir = 'db'\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=pers_dir)"
      ],
      "metadata": {
        "id": "jIdINx4IiWUm"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "EDOsoDvciWj2"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = None\n",
        "vectordb = Chroma(embedding_function=embeddings, persist_directory=pers_dir)"
      ],
      "metadata": {
        "id": "kRbwxc-AiWmf"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make a retriever"
      ],
      "metadata": {
        "id": "PBPNfGaDLRoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "XojGNe1yLWaB"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a chain"
      ],
      "metadata": {
        "id": "4zdJA-o1UPap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating chain to ans questions\n",
        "llm = GooglePalm(google_api_key=api_key)\n",
        "qa_chain = RetrievalQA.from_chain_type(llm = llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
      ],
      "metadata": {
        "id": "QBvJAveVURZg"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple function to process the response of the llm\n",
        "def process_llm_response(llm_response):\n",
        "  print(f\"Result: {llm_response['result']}\")\n",
        "  print('\\n\\nSource: ')\n",
        "  for source in llm_response['source_documents']:\n",
        "    print(source.metadata['source'])\n"
      ],
      "metadata": {
        "id": "VLSBb_3wnNld"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try it out!\n",
        "query = \"Enter your context related question here\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)\n"
      ],
      "metadata": {
        "id": "_AJUmC_WUSAG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}